{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project source: https://www.kaggle.com/datasets/mrsimple07/laptoppriceprediction?resource=download\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Brand  Processor_Speed  RAM_Size  Storage_Capacity  Screen_Size  \\\n",
      "0      Asus         3.830296        16               512    11.185147   \n",
      "1      Acer         2.912833         4              1000    11.311372   \n",
      "2    Lenovo         3.241627         4               256    11.853023   \n",
      "3      Acer         3.806248        16               512    12.280360   \n",
      "4      Acer         3.268097        32              1000    14.990877   \n",
      "..      ...              ...       ...               ...          ...   \n",
      "995      HP         3.343584         4              1000    12.587095   \n",
      "996    Dell         2.780555         8               256    12.679356   \n",
      "997    Dell         3.200569         4               512    12.666315   \n",
      "998    Asus         1.604182         8               256    11.215581   \n",
      "999  Lenovo         1.711980         4               256    16.561498   \n",
      "\n",
      "       Weight         Price  \n",
      "0    2.641094  17395.093065  \n",
      "1    3.260012  31607.605919  \n",
      "2    2.029061   9291.023542  \n",
      "3    4.573865  17436.728334  \n",
      "4    4.193472  32917.990718  \n",
      "..        ...           ...  \n",
      "995  3.162399  31593.668017  \n",
      "996  3.750265   9149.521832  \n",
      "997  3.392612  16552.404779  \n",
      "998  3.857613   9407.473459  \n",
      "999  3.440883   8807.696702  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "dataSet = pd.read_csv('Laptop_price.csv')\n",
    "X = dataSet.iloc[:, 1:-1].values\n",
    "y = dataSet.iloc[:, -1].values\n",
    "print(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "# X = np.array(columnTransformer.fit_transform(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-45 {color: black;}#sk-container-id-45 pre{padding: 0;}#sk-container-id-45 div.sk-toggleable {background-color: white;}#sk-container-id-45 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-45 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-45 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-45 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-45 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-45 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-45 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-45 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-45 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-45 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-45 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-45 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-45 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-45 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-45 div.sk-item {position: relative;z-index: 1;}#sk-container-id-45 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-45 div.sk-item::before, #sk-container-id-45 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-45 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-45 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-45 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-45 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-45 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-45 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-45 div.sk-label-container {text-align: center;}#sk-container-id-45 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-45 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-45\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" checked><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31542.47239845 18496.94999019 10462.92317901 10359.88260932\n",
      " 16997.68429281  9129.84112735 31432.17274625 17665.03124167\n",
      " 17677.5837525  31866.75121213 31762.4562232  10591.3027258\n",
      "  9679.06159469 31751.51506168 10455.01770838  9286.52069548\n",
      " 31360.58221213 17101.45450322  9595.51012388 10602.3101857\n",
      " 10469.26654974 17060.96586214 18176.11096499 31614.03420326\n",
      " 32210.28057964 17262.05095367 16970.07359504 17254.53150066\n",
      " 32178.70552    31448.2735907  31636.00932716 17105.18696943\n",
      " 18106.6165321  31618.17924856 18252.40432502 17531.54889468\n",
      " 32722.63172106  9076.23956469 16616.96728627 16830.7232342\n",
      " 33109.29829796  9345.1001932  10604.27339322 17510.75764348\n",
      " 31397.52537802 16808.83470306 31743.44815805 17025.5131289\n",
      " 31931.932453    9622.15158177 32000.60821476 16974.02022939\n",
      " 32847.83905264 31891.00531007  9756.25779995 10467.3157544\n",
      " 18143.72538127 31939.46402341 31681.93537631 31671.12131101\n",
      "  9150.88940539  9486.918415   31515.98232663 17682.13533529\n",
      " 31953.11677802 16941.62597222  9522.05093592  9474.66058898\n",
      " 31835.50374938  9282.37952278 32018.36706365 17250.85395868\n",
      "  9642.68994578 31719.68150287 18106.3545063  18170.91173854\n",
      " 31703.61459031 17245.99629151 16762.91660593 32051.08861369\n",
      "  9755.42757854 32676.13905773 31529.45063708 31372.14207834\n",
      " 16636.05705686 10570.13285653  9006.41615004 17193.19860906\n",
      " 32983.29725488 18224.81745947 17630.79382014 16829.04004017\n",
      " 10426.98803695 17409.51522854 31946.27442299  9863.85564232\n",
      " 17626.73442453  9764.14493149 10685.26098137  9553.35863394\n",
      " 10575.11457871 33056.73945094 32822.97117293 10789.16515274\n",
      " 31540.34073501 32933.03059005  9576.61993417 31915.10618932\n",
      " 31881.70081711 16858.67926521 18164.19795888 32162.13212526\n",
      " 31992.71013217  9601.5526112  32900.44982077 18165.26542825\n",
      "  9317.6879178  17203.50386651  9437.16523291 16942.24625502\n",
      " 17986.2161963  10043.88323895 17008.98909545 17563.31178649\n",
      " 16790.57943174  9776.48604286  9143.83014936 10029.44458042\n",
      " 17175.06707832 10686.71580991 16621.19028246 31252.77888117\n",
      " 10392.51159354 10718.75913974 17119.32533901 31520.70474583\n",
      " 17600.62288421 16827.90852898 32018.06401342  9324.99126253\n",
      " 10740.7520083   9218.12844292  9438.58411124 32114.80096328\n",
      "  9626.86777758 33106.97199449 17102.00887288  9223.96203291\n",
      " 31407.38463368  9278.39971953 10338.9326917  32803.75101295\n",
      " 18070.80033987 16996.98085382  9896.58505862 16870.04386822\n",
      " 32644.04039192 31787.2981383  31429.11253742 16846.70210735\n",
      " 16999.89481534 18266.59601097 18197.10747118 32059.03187816\n",
      " 31468.0306629  18305.88979712 31246.55274969 31356.82524334\n",
      "  9436.88362942 31829.7990432   9886.75020751 32263.09926217\n",
      "  9234.53909311  9841.38025113  8963.68247152 32089.69897832\n",
      " 10552.46748481 10826.77611471 31544.67406312 16755.01788095\n",
      " 17297.08833793  9007.93680525  9692.62725263 31973.89318041\n",
      " 33063.22960564 10079.34544472 16652.34075714 18297.09101411\n",
      " 31425.12705336 31322.89504536 17602.34694933 18014.40863406\n",
      "  9062.38316449  9545.88560468 32012.44621449  9511.47638872\n",
      " 16712.38397739 10842.48452295  9278.13549197  9556.91461471]\n"
     ]
    }
   ],
   "source": [
    "y_predictor = model.predict(X_test)\n",
    "# print(y_predictor)\n",
    "# print(np.concatenate((y_predictor.reshape(len(y_predictor),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model is:\n",
      "0.9996% accurate \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('Our model is:')\n",
    "r2Score = str(round(r2_score(y_test, y_predictor), 4))\n",
    "print(r2Score + '%'+ ' accurate ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32900.05499503]\n"
     ]
    }
   ],
   "source": [
    "prediction_entry = np.array([[2.7, 32, 1000, 15.00, 3.09]])\n",
    "y_predictor2 = model.predict(prediction_entry)\n",
    "print(np.array(y_predictor2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
